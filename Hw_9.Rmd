---
title: "Hw_9"
author: "Pranita"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE
)
#importing libraries and data sets
library(tidyverse)
library(mosaic)
library(moderndive)
library(effectsize)

soldering <- read_csv("solder.csv")
groceries <- read_csv("groceries.csv")
redlining <- read_csv("redlining.csv")


```

#add name + github


# Problem 1
## Part A
```{r}
# opening vs skips graph 
ggplot(soldering) + 
  geom_jitter(aes(x = Opening, y = skips), width=0.1) + 
  stat_summary(aes(x = Opening, y = skips), fun='mean', color='red', size=1) + labs(title = "Opening vs Skips for soldering", x = "Type of Opening", caption = "Comparing small, medium, and large openings on solder gun to see if there is a differnce in number of skips. \n It can be noted that the average skips for small openings are 11, for medium openings are 4 and for large openings are 2.") + theme_classic()

mean(skips ~ Opening, data=soldering) |>
  round(0)


# solder vs skips graph 
ggplot(soldering) + 
  geom_jitter(aes(x = Solder, y = skips), width=0.1) + 
  stat_summary(aes(x = Solder, y = skips), fun='mean', color='red', size=1) + labs(title = "Soldering type vs Skips for soldering", x = "Solder thickness", caption = "Comparing thick and thin alloys used to see if there is a differnce in number of skips. \n It can be noted that the average skips for thick alloys are 3, while it is 8 for thin alloys.") + theme_classic()


mean(skips ~ Solder, data=soldering) |>
  round(0)
```


## Part B


```{r}

#regression mmodel
relationship = lm(skips ~ Opening + Solder + Solder:Opening, data=soldering)
coef(relationship) |>
  round(0)



#bootstrap model for each coeff  
boot_skip <- do(100) * coef(lm(skips ~ Opening + Solder + Opening:Solder, data = resample(soldering)))

#make it a table
interval <- data.frame(apply(boot_skip, 2, quantile, probs = c(0.025, 0.975)))
interval
```
# finish writing here
Skips = 2(Opening_Medium) + 5(Opening_Small) + 2(SolderThin) - (Opening_Medium)(SolderThin) + 10 (Opening_Small)(SolderThin)




## Part C
The baseline number of skips is 0, which represents boards with a large opening and thick solder. This intercept also refers to all interactions involving these baseline levels, since their coefficients are set to zero.
The main effect for medium Openings is 2 skips, this is the effect of OpeningM in isolation. The main effect for small Openings is 5 skips, this is the effect of OpeningS in isolation. The main effect for thin solders is 2 skips, this is the effect of SolderThin in isolation. 
The interaction effect for OpeningM and SolderThin is -1 skips. In other words, circuits which had both medium openings and thin solders used average 1 less skips than what you would expect from summing the individual “isolated” effects of the two variables. 
The interaction effect for OpeningS and SolderThin is 10 skips. In other words, circuits which had both small openings and thin solders used average 10 more skips than what you would expect from summing the individual “isolated” effects of the two variables. 




## Part D
If I had to recommend a combination of opening size and solder thickness to AT&T based on this analysis I would recommend they use a large opening and a thick solder since this is the most likely to result in 0 skips, which is the lowest number of skips possible.



# Problem 2
## Part A
```{r}

#bar graph in ascednding price order
price_store <- groceries |>
  group_by (Store) |>
  summarise(avg_price = mean(Price, na.rm = TRUE))

ggplot(price_store, aes(x = avg_price, y = reorder(Store, avg_price))) + geom_col(color = "navy", fill = "lightblue") + labs(title = "Average cost of items by store", x = "Price ($)", y = "Store", caption = "Graphing the average price of products sold at each store from highest to lowest.") + theme_classic()



```

## Part B

```{r}

#mutating dataset so 2 heb and 2 whole foods will the diff stores
groceries <- groceries |>
  mutate(Store_addy = paste(Store, Neighborhood, sep = "_"))

#wrangling data
is_product <- groceries |>
  group_by(Product) |>
  summarise(Num_stores = n_distinct(Store_addy)) |>
  arrange(desc(Num_stores)) 


#graphing w caption
ggplot(is_product, aes(x = Num_stores, y = reorder(Product, Num_stores))) + geom_col(color = "navy", fill = "lightblue") + labs(title = "Number of stores certain products are found at", x = "Product", y = "Number of Stores", caption = "Graphing the average price of products sold at each store from highest to lowest.") + theme_classic()

```



## Part C

```{r}

#regression + table
model = lm(Price ~ Product + Type, data= groceries)
get_regression_table(model, conf.level = 0.95, digits=2)

#showing only grocery 
tail(t)

```

Compared with ordinary grocery stores (like Albertsons, HEB, or Krogers), convenience stores charge somewhere between 0.41 and 0.92 dollars more for the same product.


## Part D
```{r}

#wrangling - making dummy variables 
groceries <- groceries |>
  mutate(Store = as.factor(Store),
         Product = as.factor(Product))

#regression + table
model = lm(Price ~ Store + Product, data= groceries)
store_prices <- get_regression_table(model, conf.level = 0.95, digits=2)

#first two stores have lowest price
store_prices |>
  filter(str_detect(term, "Store")) |>
  arrange(estimate) 


#first two stores will have hgihest price
store_prices |>
  filter(str_detect(term, "Store")) |>
  arrange(desc(estimate)) 

```


The two stores that seem to charge the lowest prices when comparing the same products are Whole Foods and Wheatsville Food Co-Op. The two stores that seem to charge the highest prices when comparing the same products are Walmart and Kroger Fresh Fare.



## Part E
```{r}

#making heb the baseline and refitting model
heb_groceries <- groceries |>
  mutate(Store = relevel(Store, ref = "H-E-B"))

model <- lm(Price ~ Store + Product, data = heb_groceries)
get_regression_table(model, conf.level = 0.95, digits=2)

#(printing out whole table so can compare other store /see relative expense)

```

Central Market on average charges $0.07 more for the same products as HEB. This difference is not a lot especially when compared to the other stores, so we can say that by relative difference Central Market is not price discriminating when looking at HEB prices.


## Part F
```{r}

#measuring income in multiples of 10,000
income_groceries <- groceries |>
  mutate("Income10K" = trunc(Income/10000))

#model
model = lm(Price ~ Income10K + Product, data= income_groceries)
imcome_pay <- get_regression_table(model, conf.level = 0.95, digits=2)

#looking at sign 
imcome_pay |>
  filter(str_detect(term, "Income10K"))

#standardizing variables
standardize_parameters(model)

```

Based on the sign of the Income10K variable, customers in poorer ZIP codes seem to pay more. I know thing because according to the model customers in poorer ZIP codes seem to pay 1 cent more for the same product on average for every $10,000 decrease in income. Since the confidence interval of -0.03 to 0.01 includes zero we cannot say this with certainty, but based on the sign of the variable alone we can say that as the income goes up the price goes down.

One-standard deviation increase in the income of a ZIP code seems to be associated with
a 0.03 standard-deviation change in the price that consumers in that ZIP code expect to pay for the same product.


# Problem 3
## Part A
```{r}


```
